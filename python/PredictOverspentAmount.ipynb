{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58e4c02-3080-4955-84fe-a2101010dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pm4py\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pm4py.algo.transformation.log_to_features import algorithm as log_to_features\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df9f9b-259e-4d37-b64c-0af17df2291b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the Data\n",
    "The code below is used to generate the CVS file. You can also skip running it and instead load the CSV directly a few cells below.\n",
    "\n",
    "First, make sure the permit log is in the current directory, then run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb45e43b-163e-462f-b86d-0510bb9ac2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c73a96902d54c1889ca62bed6fdf31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/7065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel_permits = pm4py.read_xes('PermitLog.xes.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e1405-73f8-4be3-a1f6-03bc6fb96538",
   "metadata": {},
   "source": [
    "First, we make sure we have the prefixes we need, we just want the events leading up to 'Start trip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42947cb-0224-4eb3-ad28-24afce3789a5",
   "metadata": {},
   "source": [
    "travel_prefixes = pm4py.filtering.filter_prefixes(travel_permits, 'Start trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce862e74-17cc-4230-92ec-cf5095138874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permit SUBMITTED by EMPLOYEE\n",
      "Permit FINAL_APPROVED by SUPERVISOR\n",
      "Start trip\n",
      "End trip\n",
      "Declaration SUBMITTED by EMPLOYEE\n",
      "Declaration FINAL_APPROVED by SUPERVISOR\n",
      "Request Payment\n",
      "Payment Handled\n",
      "\n",
      "Permit SUBMITTED by EMPLOYEE\n",
      "Permit FINAL_APPROVED by SUPERVISOR\n"
     ]
    }
   ],
   "source": [
    "#quick check to see if we got what we wanted\n",
    "i = 39\n",
    "for e in travel_permits[i]:\n",
    "    print(e['concept:name'])\n",
    "print() \n",
    "for e in travel_prefixes[i]:\n",
    "    print(e['concept:name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15dfa1-941d-4d0e-8bb5-d1762d30018c",
   "metadata": {},
   "source": [
    "Check if a declaration was submitted before the trip started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e9f0b85-eec5-4096-a150-fe9fd9a0f7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decl_bools = np.zeros((7065,1))\n",
    "\n",
    "for i,t in enumerate(travel_prefixes):\n",
    "    for e in t:\n",
    "        if e['concept:name'] == \"Declaration SUBMITTED by EMPLOYEE\":\n",
    "            decl_bools[i,0] = 1\n",
    "            \n",
    "decl_bools.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25647453-9703-4174-86e8-1aa80c0d0105",
   "metadata": {},
   "source": [
    "Now extract the features we are interested in from the prefixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ed013f1-5db1-4401-9819-520a7767dd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, _ = log_to_features.apply(travel_prefixes, parameters={'num_tr_attr': [\"RequestedBudget\",\"OverspentAmount\"]})\n",
    "\n",
    "data = np.array(data).round(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21206dbc-9196-4108-a2ed-7741932eeb8f",
   "metadata": {},
   "source": [
    "However, we still need trip duration, which we will need to compute manually. We will use number of days to denote the duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d62cdf15-5449-4eb8-afbd-2bc51660a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_durations = []\n",
    "for trace in travel_permits:\n",
    "    for e in trace:\n",
    "        if e['concept:name'] == \"Start trip\": #note the time the trip started\n",
    "            start_time = e['time:timestamp']\n",
    "        elif e['concept:name'] == \"End trip\": #note the time the trip ended\n",
    "            end_time = e['time:timestamp']\n",
    "            break\n",
    "    trip_durations.append((end_time-start_time).days) #save the trip duration in days\n",
    "    \n",
    "trip_durations = np.array(trip_durations).reshape((-1,1))\n",
    "trip_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bee2c-3b37-453f-8bc4-e808d705e940",
   "metadata": {},
   "source": [
    "And we do the same in order to get the duration between the permit being submitted and the permit being approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5981c1f-967e-43b3-8410-f953680c7dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_durations = []\n",
    "for trace in travel_permits:\n",
    "    started = False\n",
    "    for e in trace:\n",
    "        if e['concept:name'].startswith(\"Permit\") and not started: #start time is the first time permit is mentioned\n",
    "            started = True\n",
    "            start_time = e['time:timestamp']\n",
    "            end_time = e['time:timestamp']\n",
    "        elif e['concept:name'].startswith(\"Permit\"): #end time is the last time permit is mentioned\n",
    "            end_time = e['time:timestamp']\n",
    "    perm_durations.append((end_time-start_time).days) #save duration of permit handling in days\n",
    "    \n",
    "perm_durations = np.array(perm_durations).reshape((-1,1))\n",
    "perm_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d6f45-e9d7-4edb-8eff-4b0dda77e093",
   "metadata": {},
   "source": [
    "Now we merge all the features we extracted into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca24b6c0-eaec-4a65-acab-4362c9715dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.concatenate((decl_bools, trip_durations, perm_durations, data), axis=1)\n",
    "#switch the trip duration index with the overspent amount, since overspent amount is what we want to predict, so it's more intuitive\n",
    "#final_data[:,[-1,-3]] = final_data[:,[-3,-1]]\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e01fa-48de-472e-8458-c250f81127ab",
   "metadata": {},
   "source": [
    "Some exploration of the data we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05f50940-3e6b-487f-8abf-bf54f9e39194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.54</td>\n",
       "      <td>-329.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.79</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6020.79</td>\n",
       "      <td>-2645.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.06</td>\n",
       "      <td>-203.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.98</td>\n",
       "      <td>-300.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.96</td>\n",
       "      <td>-114.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1    2        3        4\n",
       "0  0.0    0.0  0.0    41.61     0.00\n",
       "1  0.0   31.0  0.0   795.54  -329.51\n",
       "2  0.0    0.0  0.0    51.79     5.18\n",
       "3  0.0   21.0  0.0     0.00     0.00\n",
       "4  0.0  364.0  0.0  6020.79 -2645.71\n",
       "5  0.0    2.0  0.0   245.06  -203.97\n",
       "6  0.0    6.0  0.0     0.00     0.00\n",
       "7  0.0    3.0  0.0  1015.98  -300.01\n",
       "8  0.0    5.0  0.0     0.00     0.00\n",
       "9  0.0    5.0  0.0   156.96  -114.06"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=final_data[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a58c8-7c0b-4427-a7f5-4beeb43525f1",
   "metadata": {},
   "source": [
    "We can now save the data to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51c92c33-4130-4866-8feb-9ae6953dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ML_data2.csv', final_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4531585-b9dc-4e87-832c-a0cc06de6a9e",
   "metadata": {},
   "source": [
    "# Load the CSV\n",
    "Or skip the below cell if you already ran the above cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "472305f6-5d4c-401d-ba43-49ab0edb093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 47)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.genfromtxt('ML_data.csv',delimiter=',')\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfddb751-1710-41c6-83c4-3908e3d6688d",
   "metadata": {},
   "source": [
    "# Train the ML model\n",
    "First, we split into train, test and validation sets. We do not shuffle because for process mining it is important that the validation and test sets are further in the future than the training set. The training set is 50%, validation 25%, and test set 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2c5dfa7c-d786-45e8-90bb-7e0bdd558ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = sklearn.model_selection.train_test_split(final_data[:,:-1], final_data[:,-1], \n",
    "                                                                                  train_size=0.5, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = sklearn.model_selection.train_test_split(X_valtest, y_valtest, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a5d11-3fd0-4ae2-a95a-5ddeea635c44",
   "metadata": {},
   "source": [
    "Next, we do a parameter search and choose the best parameters based on performance on the validation set. The score metric here has a maximum value of 1.0 and no minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc6df7f1-ddb6-47ee-a1b7-9c60e7b0406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 25, min_samples_split: 1, score: -0.00018689364638735384\n",
      "n_estimators: 25, min_samples_split: 20, score: -0.0003260712066353033\n",
      "n_estimators: 25, min_samples_split: 50, score: -0.00035390510172073064\n",
      "n_estimators: 50, min_samples_split: 1, score: 4.247169866888889e-05\n",
      "n_estimators: 50, min_samples_split: 20, score: -0.00014095695085547533\n",
      "n_estimators: 50, min_samples_split: 50, score: -0.0004382467879173735\n",
      "n_estimators: 100, min_samples_split: 1, score: -0.00024208112698587136\n",
      "n_estimators: 100, min_samples_split: 20, score: -0.0002975917960832408\n",
      "n_estimators: 100, min_samples_split: 50, score: -0.00028339729521809076\n",
      "n_estimators: 200, min_samples_split: 1, score: -0.000109498449644585\n",
      "n_estimators: 200, min_samples_split: 20, score: -0.00039018104932475595\n",
      "n_estimators: 200, min_samples_split: 50, score: -0.000320108781380668\n"
     ]
    }
   ],
   "source": [
    "#no gridsearchcv because it doesn't allow for a validation set\n",
    "best_score = -10000\n",
    "for n_est, min_split in product([25,50,100,200], [1,20,50]):\n",
    "    model = RandomForestRegressor(n_estimators = n_est, min_samples_split = min_split)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    print(\"n_estimators: {}, min_samples_split: {}, score: {}\".format(n_est, min_split, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_param = n_est, min_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae813fcb-d5da-4c18-8bd3-62418fd6d350",
   "metadata": {},
   "source": [
    "Now we take the model with the best performing parameters and test its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f6f81529-518a-41cd-a8e8-ded53afbf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06066773139999637"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestRegressor(n_estimators = best_param[0], min_samples_split = best_param[1])\n",
    "best_model.fit(X_train, y_train)\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb1fe1-d04d-4b25-85b2-12a64c39e50c",
   "metadata": {},
   "source": [
    "This score metric isn't the most intuitive, so let's compute mean absolute error on the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dd4cab02-9770-44c4-821c-9be36b8e717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516.9346679294575"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9213830-5883-42dd-b1e7-8e424b071ae4",
   "metadata": {},
   "source": [
    "There is clearly still room for improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
