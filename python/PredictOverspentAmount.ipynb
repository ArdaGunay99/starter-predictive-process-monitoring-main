{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58e4c02-3080-4955-84fe-a2101010dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pm4py\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pm4py.algo.transformation.log_to_features import algorithm as log_to_features\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df9f9b-259e-4d37-b64c-0af17df2291b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the Data\n",
    "The code below is used to generate the CVS file. You can also skip running it and instead load the CSV directly a few cells below.\n",
    "\n",
    "First, make sure the permit log is in the current directory, then run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb45e43b-163e-462f-b86d-0510bb9ac2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645054b04e214ce082448ca6cb54aa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/7065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel_permits = pm4py.read_xes('PermitLog.xes.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e1405-73f8-4be3-a1f6-03bc6fb96538",
   "metadata": {},
   "source": [
    "First, we make sure we have the prefixes we need, we just want the events leading up to 'Start trip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dad6190-4c6e-4da1-9732-aa628a90b105",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidVersion",
     "evalue": "Invalid version: 'please use pm4py.algo.filtering.log.ltl.ltl_checker.eventually_follows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidVersion\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m travel_prefixes \u001b[38;5;241m=\u001b[39m \u001b[43mpm4py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiltering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_prefixes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtravel_permits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart trip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\pm4py\\filtering.py:754\u001b[0m, in \u001b[0;36mfilter_prefixes\u001b[1;34m(log, activity, strict, first_or_last)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prefix_filter\u001b[38;5;241m.\u001b[39mapply(log, activity, parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 754\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpm4py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiltering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprefixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefix_filter\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prefix_filter\u001b[38;5;241m.\u001b[39mapply(log, activity, parameters\u001b[38;5;241m=\u001b[39mparameters)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\pm4py\\algo\\filtering\\log\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m    This file is part of PM4Py (More Info: https://pm4py.fit.fraunhofer.de).\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    along with PM4Py.  If not, see <https://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpm4py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiltering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attributes, end_activities, paths, \\\n\u001b[0;32m     19\u001b[0m     cases, start_activities, timestamp, variants, ltl\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\pm4py\\algo\\filtering\\log\\ltl\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m    This file is part of PM4Py (More Info: https://pm4py.fit.fraunhofer.de).\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    along with PM4Py.  If not, see <https://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpm4py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiltering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mltl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ltl_checker\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\pm4py\\algo\\filtering\\log\\ltl\\ltl_checker.py:60\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeprecated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2.2.6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3.0.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplease use pm4py.algo.filtering.log.ltl.ltl_checker.eventually_follows\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mA_eventually_B\u001b[39m(log, A, B, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    Applies the A eventually B rule\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m        Filtered log\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\deprecation.py:170\u001b[0m, in \u001b[0;36mdeprecated\u001b[1;34m(deprecated_in, removed_in, current_version, details)\u001b[0m\n\u001b[0;32m    168\u001b[0m         is_deprecated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m current_version:\n\u001b[1;32m--> 170\u001b[0m     current_version \u001b[38;5;241m=\u001b[39m \u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (removed_in\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m current_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(removed_in)):\n\u001b[0;32m    174\u001b[0m         is_unsupported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\packaging\\version.py:52\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(version)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(version: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124;03m\"\"\"Parse the given version string.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    >>> parse('1.0.dev1')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    :raises InvalidVersion: When the version string is not a valid version.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\packaging\\version.py:197\u001b[0m, in \u001b[0;36mVersion.__init__\u001b[1;34m(self, version)\u001b[0m\n\u001b[0;32m    195\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_regex\u001b[38;5;241m.\u001b[39msearch(version)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidVersion(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid version: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Store the parsed out pieces of the version\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version \u001b[38;5;241m=\u001b[39m _Version(\n\u001b[0;32m    201\u001b[0m     epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    202\u001b[0m     release\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelease\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     local\u001b[38;5;241m=\u001b[39m_parse_local_version(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    209\u001b[0m )\n",
      "\u001b[1;31mInvalidVersion\u001b[0m: Invalid version: 'please use pm4py.algo.filtering.log.ltl.ltl_checker.eventually_follows'"
     ]
    }
   ],
   "source": [
    "travel_prefixes = pm4py.filtering.filter_prefixes(travel_permits, 'Start trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce862e74-17cc-4230-92ec-cf5095138874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check to see if we got what we wanted\n",
    "i = 39\n",
    "for e in travel_permits[i]:\n",
    "    print(e['concept:name'])\n",
    "print() \n",
    "for e in travel_prefixes[i]:\n",
    "    print(e['concept:name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15dfa1-941d-4d0e-8bb5-d1762d30018c",
   "metadata": {},
   "source": [
    "Check if a declaration was submitted before the trip started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f0b85-eec5-4096-a150-fe9fd9a0f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decl_bools = np.zeros((7065,1))\n",
    "\n",
    "for i,t in enumerate(travel_prefixes):\n",
    "    for e in t:\n",
    "        if e['concept:name'] == \"Declaration SUBMITTED by EMPLOYEE\":\n",
    "            decl_bools[i,0] = 1\n",
    "            \n",
    "decl_bools.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25647453-9703-4174-86e8-1aa80c0d0105",
   "metadata": {},
   "source": [
    "Now extract the features we are interested in from the prefixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed013f1-5db1-4401-9819-520a7767dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = log_to_features.apply(travel_prefixes, parameters={'num_tr_attr': [\"RequestedBudget\",\"OverspentAmount\"]})\n",
    "\n",
    "data = np.array(data).round(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21206dbc-9196-4108-a2ed-7741932eeb8f",
   "metadata": {},
   "source": [
    "However, we still need trip duration, which we will need to compute manually. We will use number of days to denote the duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cdf15-5449-4eb8-afbd-2bc51660a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_durations = []\n",
    "for trace in travel_permits:\n",
    "    for e in trace:\n",
    "        if e['concept:name'] == \"Start trip\": #note the time the trip started\n",
    "            start_time = e['time:timestamp']\n",
    "        elif e['concept:name'] == \"End trip\": #note the time the trip ended\n",
    "            end_time = e['time:timestamp']\n",
    "            break\n",
    "    trip_durations.append((end_time-start_time).days) #save the trip duration in days\n",
    "    \n",
    "trip_durations = np.array(trip_durations).reshape((-1,1))\n",
    "trip_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bee2c-3b37-453f-8bc4-e808d705e940",
   "metadata": {},
   "source": [
    "And we do the same in order to get the duration between the permit being submitted and the permit being approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5981c1f-967e-43b3-8410-f953680c7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_durations = []\n",
    "for trace in travel_permits:\n",
    "    started = False\n",
    "    for e in trace:\n",
    "        if e['concept:name'].startswith(\"Permit\") and not started: #start time is the first time permit is mentioned\n",
    "            started = True\n",
    "            start_time = e['time:timestamp']\n",
    "            end_time = e['time:timestamp']\n",
    "        elif e['concept:name'].startswith(\"Permit\"): #end time is the last time permit is mentioned\n",
    "            end_time = e['time:timestamp']\n",
    "    perm_durations.append((end_time-start_time).days) #save duration of permit handling in days\n",
    "    \n",
    "perm_durations = np.array(perm_durations).reshape((-1,1))\n",
    "perm_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d6f45-e9d7-4edb-8eff-4b0dda77e093",
   "metadata": {},
   "source": [
    "Now we merge all the features we extracted into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24b6c0-eaec-4a65-acab-4362c9715dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.concatenate((decl_bools, trip_durations, perm_durations, data), axis=1)\n",
    "#switch the trip duration index with the overspent amount, since overspent amount is what we want to predict, so it's more intuitive\n",
    "#final_data[:,[-1,-3]] = final_data[:,[-3,-1]]\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e01fa-48de-472e-8458-c250f81127ab",
   "metadata": {},
   "source": [
    "Some exploration of the data we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f50940-3e6b-487f-8abf-bf54f9e39194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=final_data[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a58c8-7c0b-4427-a7f5-4beeb43525f1",
   "metadata": {},
   "source": [
    "We can now save the data to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c92c33-4130-4866-8feb-9ae6953dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ML_data2.csv', final_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4531585-b9dc-4e87-832c-a0cc06de6a9e",
   "metadata": {},
   "source": [
    "# Load the CSV\n",
    "Or skip the below cell if you already ran the above cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472305f6-5d4c-401d-ba43-49ab0edb093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.genfromtxt('ML_data2.csv',delimiter=',')\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25edcd4-74c0-45c1-92ee-7300eec4529f",
   "metadata": {},
   "source": [
    "# Train the ML model\n",
    "First, we split into train, test and validation sets. We do not shuffle because for process mining it is important that the validation and test sets are further in the future than the training set. The training set is 75%, validation 12.5%, and test set 12.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c5dfa7c-d786-45e8-90bb-7e0bdd558ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = sklearn.model_selection.train_test_split(final_data[:,:-1], final_data[:,-1], \n",
    "                                                                                  train_size=0.75, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = sklearn.model_selection.train_test_split(X_valtest, y_valtest, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a5d11-3fd0-4ae2-a95a-5ddeea635c44",
   "metadata": {},
   "source": [
    "Next, we do a parameter search and choose the best parameters based on performance on the validation set. The score metric here has a maximum value of 1.0 and no minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6df7f1-ddb6-47ee-a1b7-9c60e7b0406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 25, min_samples_split: 1, score: -441.75531567269707\n",
      "n_estimators: 25, min_samples_split: 20, score: -172.83937114910827\n",
      "n_estimators: 25, min_samples_split: 50, score: -27.34968290240855\n",
      "n_estimators: 50, min_samples_split: 1, score: -209.01813180308832\n",
      "n_estimators: 50, min_samples_split: 20, score: -208.9923382991645\n",
      "n_estimators: 50, min_samples_split: 50, score: -7.816657287969825\n",
      "n_estimators: 100, min_samples_split: 1, score: -155.8107583862892\n",
      "n_estimators: 100, min_samples_split: 20, score: -291.5959409721682\n",
      "n_estimators: 100, min_samples_split: 50, score: -8.329258952731115\n",
      "n_estimators: 200, min_samples_split: 1, score: -228.116444481496\n",
      "n_estimators: 200, min_samples_split: 20, score: -208.91534192085655\n",
      "n_estimators: 200, min_samples_split: 50, score: -7.095602384430771\n"
     ]
    }
   ],
   "source": [
    "#no gridsearchcv because it doesn't allow for a validation set\n",
    "best_score = -10000\n",
    "for n_est, min_split in product([25,50,100,200], [1,20,50]):\n",
    "    model = RandomForestRegressor(n_estimators = n_est, min_samples_split = min_split)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    print(\"n_estimators: {}, min_samples_split: {}, score: {}\".format(n_est, min_split, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_param = n_est, min_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae813fcb-d5da-4c18-8bd3-62418fd6d350",
   "metadata": {},
   "source": [
    "Now we take the model with the best performing parameters and test its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f81529-518a-41cd-a8e8-ded53afbf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.047660646121992"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestRegressor(n_estimators = best_param[0], min_samples_split = best_param[1])\n",
    "best_model.fit(X_train, y_train)\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb1fe1-d04d-4b25-85b2-12a64c39e50c",
   "metadata": {},
   "source": [
    "This score metric isn't the most intuitive, so let's compute mean absolute error on the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4cab02-9770-44c4-821c-9be36b8e717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924.2105526147691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ecf732-fcee-4aa1-84bd-e2adc82711d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Definition ##\n",
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f25e82-6e3c-4192-b554-6779f6ce9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0895515-ad94-4a87-8c62-467349d9a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        input_layer = torch.nn.Linear(4,16)\n",
    "        hidden_layer = torch.nn.Linear(16, 16)\n",
    "        output_layer = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = input_layer(x)\n",
    "        x = hidden_layer(x)\n",
    "        x = output_layer(x)\n",
    "        return x\n",
    "\n",
    "model = Model().to(device)\n",
    "#summary(model, input_size=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c4d8dd-2b8a-49b3-83a7-678b64652b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## LOSS Definition ##\u001b[39;00m\n\u001b[0;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, momentum=0.5, weight_decay=1e-5)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\torch\\optim\\adam.py:137\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(weight_decay))\n\u001b[0;32m    133\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    134\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    135\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    136\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PROM\\lib\\site-packages\\torch\\optim\\optimizer.py:61\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     59\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     63\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "## LOSS Definition ##\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#, momentum=0.5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a306eb79-8049-4ea9-a40d-b43a7353adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training ##\n",
    "#Trainer class from the practical, adapted slightly because we do not have a validation set\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 epochs: int,\n",
    "                 mean_train_losses,\n",
    "                 mean_val_losses\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.mean_train_losses = mean_train_losses\n",
    "        self.mean_val_losses = mean_val_losses\n",
    "\n",
    "    def run_trainer(self):\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            \n",
    "            self.model.train()  # train mode\n",
    "            #idx = [range(X_train.shape[0])]\n",
    "            #batches = idx.split(self.batch_size)\n",
    "\n",
    "            train_losses=[]\n",
    "            for batch in range(X_train.shape[0]):\n",
    "                x,y=X_train[batch], y_train[batch]\n",
    "                input, target = x.to(self.device), y.to(self.device).reshape((-1,1))  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target).cpu()  # calculate loss\n",
    "\n",
    "                train_losses.append(float(loss))\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "\n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f\"LOSS: {np.mean(train_losses):.4f}\")\n",
    "            self.mean_train_losses.append(np.mean(train_losses))\n",
    "            \n",
    "            val_losses=[]\n",
    "            for batch in range(X_val.shape[0]):\n",
    "                self.model.eval()\n",
    "                x,y=X_val[batch], y_val[batch]\n",
    "                input, target = x.to(self.device), y.to(self.device).reshape((-1,1))  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target).cpu()  # calculate loss\n",
    "\n",
    "                val_losses.append(float(loss))\n",
    "                \n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f\"LOSS: {np.mean(val_losses):.4f}\")\n",
    "            self.mean_val_losses.append(np.mean(val_losses))\n",
    "\n",
    "\n",
    "        def test(self):\n",
    "            model = trainer.model.to(\"cpu\")\n",
    "            model.eval()\n",
    "            test_losses=[]\n",
    "            for batch in range(X_test.shape[0]):\n",
    "                #self.model.eval()\n",
    "                x,y=X_test[batch], y_test[batch]\n",
    "                input, target = x.to(self.device), y.to(self.device).reshape((-1,1))  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target).cpu()  # calculate loss\n",
    "\n",
    "                test_losses.append(float(loss))\n",
    "                \n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f\"LOSS: {np.mean(test_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "618899fc-1dd1-494b-8e9d-1953adfd5945",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      2\u001b[0m                   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m      3\u001b[0m                   criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m----> 4\u001b[0m                   optimizer\u001b[38;5;241m=\u001b[39m\u001b[43moptimizer\u001b[49m,\n\u001b[0;32m      5\u001b[0m                   epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m      6\u001b[0m                   mean_losses\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun_trainer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  epochs=200,\n",
    "                  mean_losses=[])\n",
    "\n",
    "trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "945db8db-d248-43f4-b90c-b0d0223b4b23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mtest()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782fc7a-48dc-49dc-afc5-b3689c49d86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5ca64-1343-42d6-bad6-91d1e3095327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
