{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58e4c02-3080-4955-84fe-a2101010dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pm4py\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pm4py.algo.transformation.log_to_features import algorithm as log_to_features\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df9f9b-259e-4d37-b64c-0af17df2291b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the Data\n",
    "The code below is used to generate the CVS file. You can also skip running it and instead load the CSV directly a few cells below.\n",
    "\n",
    "First, make sure the permit log is in the current directory, then run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb45e43b-163e-462f-b86d-0510bb9ac2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd389ced8794dfe80853602c51cdb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/7065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel_permits = pm4py.read_xes('PermitLog.xes.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e1405-73f8-4be3-a1f6-03bc6fb96538",
   "metadata": {},
   "source": [
    "First, we make sure we have the prefixes we need, we just want the events leading up to 'Start trip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dad6190-4c6e-4da1-9732-aa628a90b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_prefixes = pm4py.filtering.filter_prefixes(travel_permits, 'Start trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce862e74-17cc-4230-92ec-cf5095138874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permit SUBMITTED by EMPLOYEE\n",
      "Permit FINAL_APPROVED by SUPERVISOR\n",
      "Start trip\n",
      "End trip\n",
      "Declaration SUBMITTED by EMPLOYEE\n",
      "Declaration FINAL_APPROVED by SUPERVISOR\n",
      "Request Payment\n",
      "Payment Handled\n",
      "\n",
      "Permit SUBMITTED by EMPLOYEE\n",
      "Permit FINAL_APPROVED by SUPERVISOR\n"
     ]
    }
   ],
   "source": [
    "#quick check to see if we got what we wanted\n",
    "i = 39\n",
    "for e in travel_permits[i]:\n",
    "    print(e['concept:name'])\n",
    "print() \n",
    "for e in travel_prefixes[i]:\n",
    "    print(e['concept:name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15dfa1-941d-4d0e-8bb5-d1762d30018c",
   "metadata": {},
   "source": [
    "Check if a declaration was submitted before the trip started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9f0b85-eec5-4096-a150-fe9fd9a0f7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decl_bools = np.zeros((7065,1))\n",
    "\n",
    "for i,t in enumerate(travel_prefixes):\n",
    "    for e in t:\n",
    "        if e['concept:name'] == \"Declaration SUBMITTED by EMPLOYEE\":\n",
    "            decl_bools[i,0] = 1\n",
    "            \n",
    "decl_bools.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25647453-9703-4174-86e8-1aa80c0d0105",
   "metadata": {},
   "source": [
    "Now extract the features we are interested in from the prefixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed013f1-5db1-4401-9819-520a7767dd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, _ = log_to_features.apply(travel_prefixes, parameters={'num_tr_attr': [\"RequestedBudget\",\"OverspentAmount\"]})\n",
    "\n",
    "data = np.array(data).round(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21206dbc-9196-4108-a2ed-7741932eeb8f",
   "metadata": {},
   "source": [
    "However, we still need trip duration, which we will need to compute manually. We will use number of days to denote the duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62cdf15-5449-4eb8-afbd-2bc51660a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_durations = []\n",
    "for trace in travel_permits:\n",
    "    for e in trace:\n",
    "        if e['concept:name'] == \"Start trip\": #note the time the trip started\n",
    "            start_time = e['time:timestamp']\n",
    "        elif e['concept:name'] == \"End trip\": #note the time the trip ended\n",
    "            end_time = e['time:timestamp']\n",
    "            break\n",
    "    trip_durations.append((end_time-start_time).days) #save the trip duration in days\n",
    "    \n",
    "trip_durations = np.array(trip_durations).reshape((-1,1))\n",
    "trip_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bee2c-3b37-453f-8bc4-e808d705e940",
   "metadata": {},
   "source": [
    "And we do the same in order to get the duration between the permit being submitted and the permit being approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5981c1f-967e-43b3-8410-f953680c7dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_durations = []\n",
    "for trace in travel_permits:\n",
    "    started = False\n",
    "    for e in trace:\n",
    "        if e['concept:name'].startswith(\"Permit\") and not started: #start time is the first time permit is mentioned\n",
    "            started = True\n",
    "            start_time = e['time:timestamp']\n",
    "            end_time = e['time:timestamp']\n",
    "        elif e['concept:name'].startswith(\"Permit\"): #end time is the last time permit is mentioned\n",
    "            end_time = e['time:timestamp']\n",
    "    perm_durations.append((end_time-start_time).days) #save duration of permit handling in days\n",
    "    \n",
    "perm_durations = np.array(perm_durations).reshape((-1,1))\n",
    "perm_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d6f45-e9d7-4edb-8eff-4b0dda77e093",
   "metadata": {},
   "source": [
    "Now we merge all the features we extracted into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca24b6c0-eaec-4a65-acab-4362c9715dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.concatenate((decl_bools, trip_durations, perm_durations, data), axis=1)\n",
    "#switch the trip duration index with the overspent amount, since overspent amount is what we want to predict, so it's more intuitive\n",
    "#final_data[:,[-1,-3]] = final_data[:,[-3,-1]]\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e01fa-48de-472e-8458-c250f81127ab",
   "metadata": {},
   "source": [
    "Some exploration of the data we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f50940-3e6b-487f-8abf-bf54f9e39194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>795.54</td>\n",
       "      <td>-329.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.79</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6020.79</td>\n",
       "      <td>-2645.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.06</td>\n",
       "      <td>-203.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.98</td>\n",
       "      <td>-300.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.96</td>\n",
       "      <td>-114.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1    2        3        4\n",
       "0  0.0    0.0  0.0    41.61     0.00\n",
       "1  0.0   31.0  0.0   795.54  -329.51\n",
       "2  0.0    0.0  0.0    51.79     5.18\n",
       "3  0.0   21.0  0.0     0.00     0.00\n",
       "4  0.0  364.0  0.0  6020.79 -2645.71\n",
       "5  0.0    2.0  0.0   245.06  -203.97\n",
       "6  0.0    6.0  0.0     0.00     0.00\n",
       "7  0.0    3.0  0.0  1015.98  -300.01\n",
       "8  0.0    5.0  0.0     0.00     0.00\n",
       "9  0.0    5.0  0.0   156.96  -114.06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=final_data[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a58c8-7c0b-4427-a7f5-4beeb43525f1",
   "metadata": {},
   "source": [
    "We can now save the data to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c92c33-4130-4866-8feb-9ae6953dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ML_data2.csv', final_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4531585-b9dc-4e87-832c-a0cc06de6a9e",
   "metadata": {},
   "source": [
    "# Load the CSV\n",
    "Or skip the below cell if you already ran the above cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472305f6-5d4c-401d-ba43-49ab0edb093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.genfromtxt('ML_data2.csv',delimiter=',')\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25edcd4-74c0-45c1-92ee-7300eec4529f",
   "metadata": {},
   "source": [
    "# Train the ML model\n",
    "First, we split into train, test and validation sets. We do not shuffle because for process mining it is important that the validation and test sets are further in the future than the training set. The training set is 75%, validation 12.5%, and test set 12.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c5dfa7c-d786-45e8-90bb-7e0bdd558ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = sklearn.model_selection.train_test_split(final_data[:,:-1], final_data[:,-1], \n",
    "                                                                                  train_size=0.75, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = sklearn.model_selection.train_test_split(X_valtest, y_valtest, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a5d11-3fd0-4ae2-a95a-5ddeea635c44",
   "metadata": {},
   "source": [
    "Next, we do a parameter search and choose the best parameters based on performance on the validation set. The score metric here has a maximum value of 1.0 and no minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215385f-65b7-4933-ae38-5a200ba9a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "##no gridsearchcv because it doesn't allow for a validation set\n",
    "#best_score = -10000\n",
    "#for n_est, min_split in product([25,50,100,200], [1,20,50]):\n",
    "#    model = RandomForestRegressor(n_estimators = n_est, min_samples_split = min_split)\n",
    "#    model.fit(X_train, y_train)\n",
    "#    score = model.score(X_val, y_val)\n",
    "#    print(\"n_estimators: {}, min_samples_split: {}, score: {}\".format(n_est, min_split, score))\n",
    "#    if score > best_score:\n",
    "#        best_score = score\n",
    "#        best_param = n_est, min_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae813fcb-d5da-4c18-8bd3-62418fd6d350",
   "metadata": {},
   "source": [
    "Now we take the model with the best performing parameters and test its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f81529-518a-41cd-a8e8-ded53afbf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.762939633906893"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_model = RandomForestRegressor(n_estimators = best_param[0], min_samples_split = best_param[1])\n",
    "#best_model.fit(X_train, y_train)\n",
    "#best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb1fe1-d04d-4b25-85b2-12a64c39e50c",
   "metadata": {},
   "source": [
    "This score metric isn't the most intuitive, so let's compute mean absolute error on the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd4cab02-9770-44c4-821c-9be36b8e717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917.8550120609247"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean_absolute_error(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ecf732-fcee-4aa1-84bd-e2adc82711d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Definition ##\n",
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9f25e82-6e3c-4192-b554-6779f6ce9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0895515-ad94-4a87-8c62-467349d9a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 16]              80\n",
      "            Linear-2                   [-1, 16]             272\n",
      "            Linear-3                    [-1, 1]              17\n",
      "================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_layer = torch.nn.Linear(4,16)\n",
    "        self.hidden_layer = torch.nn.Linear(16, 16)\n",
    "        self.output_layer = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "model = Model().to(device)\n",
    "summary(model, input_size=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c4d8dd-2b8a-49b3-83a7-678b64652b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSS Definition ##\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#, momentum=0.5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a306eb79-8049-4ea9-a40d-b43a7353adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training ##\n",
    "#Trainer class from the practical, adapted slightly because we do not have a validation set\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 epochs: int,\n",
    "                 mean_train_losses,\n",
    "                 mean_val_losses\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.mean_train_losses = mean_train_losses\n",
    "        self.mean_val_losses = mean_val_losses\n",
    "\n",
    "    def run_trainer(self):\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            \n",
    "            self.model.train()  # train mode\n",
    "            #idx = [range(X_train.shape[0])]\n",
    "            #batches = idx.split(self.batch_size)\n",
    "            model.float()\n",
    "            train_losses=[]\n",
    "            for batch in range(X_train.shape[0]):\n",
    "                #X_train.astype(double), y_train.astype(double)\n",
    "                x,y=torch.as_tensor(X_train[batch]), torch.as_tensor(y_train[batch])\n",
    "                input, target = x.to(self.device), y.to(self.device).reshape((-1,1))  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target).cpu()  # calculate loss\n",
    "\n",
    "                train_losses.append(float(loss))\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "\n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f\"LOSS: {np.mean(train_losses):.4f}\")\n",
    "            self.mean_train_losses.append(np.mean(train_losses))\n",
    "            \n",
    "            val_losses=[]\n",
    "            for batch in range(X_val.shape[0]):\n",
    "                self.model.eval()\n",
    "                #X_val.astype(double), y_val.astype(double)\n",
    "                x,y=torch.as_tensor(X_val[batch]), torch.as_tensor(y_val[batch])\n",
    "                input, target = x.to(self.device), y.to(self.device).reshape((-1,1))  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target).cpu()  # calculate loss\n",
    "\n",
    "                val_losses.append(float(loss))\n",
    "                \n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f\"LOSS: {np.mean(val_losses):.4f}\")\n",
    "            self.mean_val_losses.append(np.mean(val_losses))\n",
    "\n",
    "\n",
    "        def test(self):\n",
    "            model = trainer.model.to(\"cpu\")\n",
    "            model.eval()\n",
    "            test_losses=[]\n",
    "            for batch in range(X_test.shape[0]):\n",
    "                #self.model.eval()\n",
    "                #X_test.astype(double), y_test.astype(double)\n",
    "                x,y=torch.as_tensor(X_test[batch]), torch.as_tensor(y_test[batch])\n",
    "                input, target = x.to(self.device), y.to(self.device).reshape((-1,1))  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target).cpu()  # calculate loss\n",
    "\n",
    "                test_losses.append(float(loss))\n",
    "                \n",
    "            print(f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}', end=' ')\n",
    "            print(f\"LOSS: {np.mean(test_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "618899fc-1dd1-494b-8e9d-1953adfd5945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      2\u001b[0m                   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m      3\u001b[0m                   criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m                   mean_val_losses\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      8\u001b[0m                  )\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 36\u001b[0m, in \u001b[0;36mTrainer.run_trainer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28minput\u001b[39m, target \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# send to device (GPU or CPU)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# zerograd the parameters\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# one forward pass\u001b[39;00m\n\u001b[0;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(out, target)\u001b[38;5;241m.\u001b[39mcpu()  \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PROM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer(x)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PROM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PROM\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  epochs=20,\n",
    "                  mean_train_losses=[],\n",
    "                  mean_val_losses=[]\n",
    "                 )\n",
    "\n",
    "trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945db8db-d248-43f4-b90c-b0d0223b4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782fc7a-48dc-49dc-afc5-b3689c49d86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ca5ca64-1343-42d6-bad6-91d1e3095327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9551253c-cc44-43b0-a419-5a6ef66406e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.  ,    0.  ,    0.  ,   41.61],\n",
       "       [   0.  ,   31.  ,    0.  ,  795.54],\n",
       "       [   0.  ,    0.  ,    0.  ,   51.79],\n",
       "       ...,\n",
       "       [   0.  ,    3.  ,    5.  , 1874.08],\n",
       "       [   0.  ,    9.  ,    8.  , 2772.68],\n",
       "       [   0.  ,    7.  ,    0.  , 1984.32]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6f36b-1bde-48fd-9353-71625b0f0a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
