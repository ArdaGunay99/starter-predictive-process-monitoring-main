{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a58e4c02-3080-4955-84fe-a2101010dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pm4py\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pm4py.algo.transformation.log_to_features import algorithm as log_to_features\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df9f9b-259e-4d37-b64c-0af17df2291b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Prepare the Data\n",
    "The code below is used to generate the CVS file. You can also skip running it and instead load the CSV directly a few cells below.\n",
    "\n",
    "First, make sure the permit log is in the current directory, then run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb45e43b-163e-462f-b86d-0510bb9ac2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04f7d30ceff4d47baf0fb5683c32211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/7065 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel_permits = pm4py.read_xes('PermitLog.xes.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e1405-73f8-4be3-a1f6-03bc6fb96538",
   "metadata": {},
   "source": [
    "First, we make sure we have the prefixes we need, we just want the events leading up to 'Start trip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffd75206-d9c1-400a-bdb1-01fba2c85c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_prefixes = pm4py.filtering.filter_prefixes(travel_permits, 'Start trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce862e74-17cc-4230-92ec-cf5095138874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permit SUBMITTED by EMPLOYEE\n",
      "Permit FINAL_APPROVED by SUPERVISOR\n",
      "Start trip\n",
      "End trip\n",
      "Declaration SUBMITTED by EMPLOYEE\n",
      "Declaration FINAL_APPROVED by SUPERVISOR\n",
      "Request Payment\n",
      "Payment Handled\n",
      "\n",
      "Permit SUBMITTED by EMPLOYEE\n",
      "Permit FINAL_APPROVED by SUPERVISOR\n"
     ]
    }
   ],
   "source": [
    "#quick check to see if we got what we wanted\n",
    "i = 39\n",
    "for e in travel_permits[i]:\n",
    "    print(e['concept:name'])\n",
    "print() \n",
    "for e in travel_prefixes[i]:\n",
    "    print(e['concept:name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25647453-9703-4174-86e8-1aa80c0d0105",
   "metadata": {},
   "source": [
    "Now extract the features we are interested in from the prefixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ed013f1-5db1-4401-9819-520a7767dd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 46)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, _ = log_to_features.apply(travel_prefixes, parameters={\"str_ev_attr\": [\"concept:name\"], \n",
    "                                                             'num_tr_attr': [\"RequestedBudget\",\"OverspentAmount\"]})\n",
    "\n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21206dbc-9196-4108-a2ed-7741932eeb8f",
   "metadata": {},
   "source": [
    "However, we still need trip duration, which we will need to compute manually. We will use number of days to denote the duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d62cdf15-5449-4eb8-afbd-2bc51660a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_durations = []\n",
    "i = 0\n",
    "for trace in travel_permits:\n",
    "    for e in trace:\n",
    "        if e['concept:name'] == \"Start trip\":\n",
    "            start_time = e['time:timestamp']\n",
    "        elif e['concept:name'] == \"End trip\":\n",
    "            end_time = e['time:timestamp']\n",
    "            break\n",
    "    trip_durations.append((end_time-start_time).days)\n",
    "    \n",
    "trip_durations = np.array(trip_durations).reshape((-1,1))\n",
    "trip_durations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d6f45-e9d7-4edb-8eff-4b0dda77e093",
   "metadata": {},
   "source": [
    "Now we merge the trip duration feature with the data we just extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ca24b6c0-eaec-4a65-acab-4362c9715dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 47)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.concatenate((data, trip_durations), axis=1)\n",
    "#switch the trip duration index with the overspent amount, since overspent amount is what we want to predict, so it's more intuitive\n",
    "final_data[:,[-1,-2]] = final_data[:,[-2,-1]]\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a58c8-7c0b-4427-a7f5-4beeb43525f1",
   "metadata": {},
   "source": [
    "We can now save the data to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51c92c33-4130-4866-8feb-9ae6953dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ML_data.csv', final_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4531585-b9dc-4e87-832c-a0cc06de6a9e",
   "metadata": {},
   "source": [
    "# Load the CSV\n",
    "Or skip the below cell if you already ran the above cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "472305f6-5d4c-401d-ba43-49ab0edb093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7065, 47)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = np.genfromtxt('ML_data.csv',delimiter=',')\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfddb751-1710-41c6-83c4-3908e3d6688d",
   "metadata": {},
   "source": [
    "# Train the ML model\n",
    "First, we split into train, test and validation sets. We do not shuffle because for process mining it is important that the validation and test sets are further in the future than the training set. The training set is 50%, validation 25%, and test set 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2c5dfa7c-d786-45e8-90bb-7e0bdd558ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = sklearn.model_selection.train_test_split(final_data[:,:-1], final_data[:,-1], \n",
    "                                                                                  train_size=0.5, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = sklearn.model_selection.train_test_split(X_valtest, y_valtest, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a5d11-3fd0-4ae2-a95a-5ddeea635c44",
   "metadata": {},
   "source": [
    "Next, we do a parameter search and choose the best parameters based on performance on the validation set. The score metric here has a maximum value of 1.0 and no minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc6df7f1-ddb6-47ee-a1b7-9c60e7b0406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 25, min_samples_split: 1, score: -0.00018689364638735384\n",
      "n_estimators: 25, min_samples_split: 20, score: -0.0003260712066353033\n",
      "n_estimators: 25, min_samples_split: 50, score: -0.00035390510172073064\n",
      "n_estimators: 50, min_samples_split: 1, score: 4.247169866888889e-05\n",
      "n_estimators: 50, min_samples_split: 20, score: -0.00014095695085547533\n",
      "n_estimators: 50, min_samples_split: 50, score: -0.0004382467879173735\n",
      "n_estimators: 100, min_samples_split: 1, score: -0.00024208112698587136\n",
      "n_estimators: 100, min_samples_split: 20, score: -0.0002975917960832408\n",
      "n_estimators: 100, min_samples_split: 50, score: -0.00028339729521809076\n",
      "n_estimators: 200, min_samples_split: 1, score: -0.000109498449644585\n",
      "n_estimators: 200, min_samples_split: 20, score: -0.00039018104932475595\n",
      "n_estimators: 200, min_samples_split: 50, score: -0.000320108781380668\n"
     ]
    }
   ],
   "source": [
    "#no gridsearchcv because it doesn't allow for a validation set\n",
    "best_score = -10000\n",
    "for n_est, min_split in product([25,50,100,200], [1,20,50]):\n",
    "    model = RandomForestRegressor(n_estimators = n_est, min_samples_split = min_split)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    print(\"n_estimators: {}, min_samples_split: {}, score: {}\".format(n_est, min_split, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_param = n_est, min_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae813fcb-d5da-4c18-8bd3-62418fd6d350",
   "metadata": {},
   "source": [
    "Now we take the model with the best performing parameters and test its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f6f81529-518a-41cd-a8e8-ded53afbf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06066773139999637"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestRegressor(n_estimators = best_param[0], min_samples_split = best_param[1])\n",
    "best_model.fit(X_train, y_train)\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb1fe1-d04d-4b25-85b2-12a64c39e50c",
   "metadata": {},
   "source": [
    "This score metric isn't the most intuitive, so let's compute mean absolute error on the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dd4cab02-9770-44c4-821c-9be36b8e717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516.9346679294575"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9213830-5883-42dd-b1e7-8e424b071ae4",
   "metadata": {},
   "source": [
    "There is clearly still room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7302a7-4073-4297-ae1a-699aa782cd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
